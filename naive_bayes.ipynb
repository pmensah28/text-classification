{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TEXT CLASSIFICATION USING NAIVE-BAYES WITH LAPLACE SMOOTHING\n",
        "\n",
        "We're going to train a naive-bayes model to predict the label (language) given a sequence of text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LdsqmKD5JoLI"
      },
      "outputs": [],
      "source": [
        "# We are going to use the Naive Bayes algorithm for language modeling.\n",
        "import io\n",
        "import math\n",
        "import operator\n",
        "from typing import List, Tuple, Dict\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `read_data` function takes in the text file and split the sentence and the corresponding label into a list of tuples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Vkj76zGIJxp-"
      },
      "outputs": [],
      "source": [
        "#First let create a function to load the dataset\n",
        "def read_data(filename:str) -> List[Tuple]: \n",
        "  files = io.open(filename, 'r', encoding='utf-8')\n",
        "  data = []\n",
        "  for lines in files:\n",
        "    tokens = lines.split() # by default this splits each line by tab, spaces and newline character\n",
        "    data.append((tokens[0], tokens[1:]))\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('__label__de', ['Ich', 'würde', 'alles', 'tun,', 'um', 'dich', 'zu', 'beschützen.']), ('__label__de', ['Tom', 'ist', 'an', 'Kunst', 'völlig', 'uninteressiert.']), ('__label__hu', ['Végeztem', 'Tomival.'])]\n"
          ]
        }
      ],
      "source": [
        "data = read_data('data/train1.txt') # load the dataset \n",
        "print(data[:3]) # print first 3 tuples in the list [label, sentence]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVpC80oOnbdF"
      },
      "source": [
        "### Count number of words\n",
        "\n",
        "`n_examples` is the total number of examples (number of sentences).\n",
        "\n",
        "`n_words_per_label` is the total number of words for a given label. Given a particular label, what is the total number of words.\n",
        "\n",
        "`label_counts` is the number of times a given label appears in the training data. ie. how many times does a given class label appears in the dataset.\n",
        "\n",
        "`word_counts` is the number of times a word appears with a given label. ie. Given a particular class, how many times does a particular word occur.\n",
        "\n",
        "It will be convinient to save the results in a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NJMmbtgfQlf7"
      },
      "outputs": [],
      "source": [
        "def word_count(data:str) -> Dict:\n",
        "  # initialize counts\n",
        "  n_examples = 0\n",
        "  n_words_per_label = defaultdict(lambda: 0)\n",
        "  label_counts = defaultdict(lambda: 0)\n",
        "  word_counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
        "\n",
        "  for example in data:\n",
        "    label, sentence = example\n",
        "    n_examples += 1\n",
        "    label_counts[label] += 1\n",
        "    n_words_per_label[label] += len(sentence)\n",
        "\n",
        "    for words in sentence:\n",
        "      word_counts[label][words] += 1\n",
        "\n",
        "  return {'n_examples': n_examples, 'n_words_per_label': n_words_per_label, 'label_counts': label_counts, 'word_counts': word_counts}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_rR4blek0Gi1"
      },
      "outputs": [],
      "source": [
        "counts = word_count(data) # Load the data for counting "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Show all counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts['n_examples'] # show the total number of examples (size of dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "id": "ulIMV4e10M0w"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('__label__en', 21352),\n",
              " ('__label__it', 12946),\n",
              " ('__label__ru', 12293),\n",
              " ('__label__tr', 12130),\n",
              " ('__label__eo', 10741),\n",
              " ('__label__de', 8147),\n",
              " ('__label__fr', 6890),\n",
              " ('__label__pt', 5838),\n",
              " ('__label__es', 5390),\n",
              " ('__label__hu', 4273)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(counts['label_counts'].items(), key=operator.itemgetter(1), reverse=True) # Get the number of times a particular label appears in the dataset.\n",
        "# We can see that english words dominates the examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('__label__en', 164223),\n",
              " ('__label__it', 76489),\n",
              " ('__label__eo', 76302),\n",
              " ('__label__ru', 70468),\n",
              " ('__label__de', 64636),\n",
              " ('__label__tr', 60013),\n",
              " ('__label__fr', 52233),\n",
              " ('__label__pt', 39808),\n",
              " ('__label__es', 37741),\n",
              " ('__label__hu', 22400)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(counts['n_words_per_label'].items(), key=operator.itemgetter(1), reverse=True) # Get the number of words for a given label\n",
        "\n",
        "#again we have a lot of english words followed by italian etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preprocessing of labels\n",
        "\n",
        "As we can see the label is not really readable hence, we need some preprocessing. eg. __label__en -> english, __label__it -> italian etc). This will be meaningful for the classification problems.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define a dictionary that maps the original label to the new.\n",
        "label_mapping = {\n",
        "    '__label__en': 'english',\n",
        "    '__label__it': 'italian',\n",
        "    '__label__eo': 'esperanto',\n",
        "    '__label__ru': 'russian',\n",
        "    '__label__de': 'german',\n",
        "    '__label__tr': 'turkish',\n",
        "    '__label__fr': 'french',\n",
        "    '__label__pt': 'portuguese',\n",
        "    '__label__es': 'spanish',\n",
        "    '__label__hu': 'hungarian'\n",
        "}\n",
        "\n",
        "\n",
        "# define the the label preprocessing function\n",
        "def rename_label(data:List[Tuple], label_mapping:Dict) -> List[Tuple]:\n",
        "    \"\"\"\n",
        "    parameter:\n",
        "    data (list of tuples): The dataset where each tuple is (label, sentence)\n",
        "    label_mapping (dictionary): The dictionary that maps old labels to new labels\n",
        "\n",
        "    Returns: \n",
        "    renamed_data (list of tuples): dataset with renamed labels\n",
        "    \n",
        "    \"\"\"\n",
        "    preprocesed_data = []\n",
        "    for label, sentence in data:\n",
        "        if label in label_mapping:\n",
        "            new_label = label_mapping[label]\n",
        "            preprocesed_data.append((new_label, sentence))\n",
        "\n",
        "        else: \n",
        "            preprocesed_data.append((label, sentence))\n",
        "\n",
        "    return preprocesed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "preprocesed_data = rename_label(data, label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('german', ['Ich', 'würde', 'alles', 'tun,', 'um', 'dich', 'zu', 'beschützen.']), ('german', ['Tom', 'ist', 'an', 'Kunst', 'völlig', 'uninteressiert.']), ('hungarian', ['Végeztem', 'Tomival.'])]\n"
          ]
        }
      ],
      "source": [
        "print(preprocesed_data[:3]) # looks great now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Great, let's now pass this through the count function!\n",
        "preprocesed_count = word_count(preprocesed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('english', 21352),\n",
              " ('italian', 12946),\n",
              " ('russian', 12293),\n",
              " ('turkish', 12130),\n",
              " ('esperanto', 10741),\n",
              " ('german', 8147),\n",
              " ('french', 6890),\n",
              " ('portuguese', 5838),\n",
              " ('spanish', 5390),\n",
              " ('hungarian', 4273)]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted(preprocesed_count['label_counts'].items(), key=operator.itemgetter(1), reverse=True) # Get the number of times a particular label appears in the dataset.\n",
        "# This looks great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hbiMVOqc5-Oz"
      },
      "outputs": [],
      "source": [
        "def predict(sentence:List, mu:float, label_counts:Dict, word_counts:Dict, n_examples:int, n_words_per_label:Dict)->str:\n",
        "  best_label = None\n",
        "  best_score = float('-inf')\n",
        "\n",
        "  for label in word_counts.keys():\n",
        "    score = 0\n",
        "    prior = label_counts[label] / sum(label_counts.values()) # calculate the prior\n",
        "\n",
        "    score += math.log(prior)\n",
        "\n",
        "    for word in sentence:\n",
        "      word_count = word_counts[label][word]\n",
        "      total_words = n_words_per_label[label]\n",
        "      vocab_size = len(word_counts[label])\n",
        "\n",
        "      word_probability = (mu + word_count) / (mu * vocab_size + total_words)  # likelihood with laplacian smoothing\n",
        "      score += math.log(word_probability) # log-likelihood.\n",
        "\n",
        "    # update the scores\n",
        "    if score > best_score:\n",
        "      best_score = score\n",
        "      best_label = label\n",
        "\n",
        "  return best_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YAxtyxYbq-t",
        "outputId": "73c1aefa-275c-443f-e46a-3e39d8a026c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "english\n"
          ]
        }
      ],
      "source": [
        "# Check results with simple example\n",
        "\n",
        "sentence = ['whats up', 'guys', 'how', 'far']\n",
        "mu = 1.0  # Laplace smoothing parameter\n",
        "counts = word_count(preprocesed_data)\n",
        "predicted_label = predict(sentence, mu, counts['label_counts'], counts['word_counts'], counts['n_examples'], counts['n_words_per_label'])\n",
        "print(predicted_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "italian\n"
          ]
        }
      ],
      "source": [
        "# Check results with simple example \n",
        "\n",
        "sentence = ['Questo', 'è', 'un', 'esempio', 'di', 'frase']\n",
        "mu = 1.0  # Laplace smoothing parameter\n",
        "counts = word_count(preprocesed_data)\n",
        "predicted_label = predict(sentence, mu, counts['label_counts'], counts['word_counts'], counts['n_examples'], counts['n_words_per_label'])\n",
        "print(predicted_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "uGgfRNu3c0tU"
      },
      "outputs": [],
      "source": [
        "# Let's compute the accuracy.\n",
        "def compute_accuracy(valid_data:List[Tuple[str, List[str]]], mu:float, counts:Dict):\n",
        "  correct_predictions = 0\n",
        "  for label, sentence in valid_data:\n",
        "    predicted_label = predict(sentence, mu, counts['label_counts'], counts['word_counts'], counts['n_examples'], counts['n_words_per_label'])\n",
        "    if predicted_label == label:\n",
        "      correct_predictions += 1\n",
        "\n",
        "  accuracy = correct_predictions / len(valid_data)\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "DEvclY-zW6gK"
      },
      "outputs": [],
      "source": [
        "# compute accuracy on validation set\n",
        "mu=1.0 # ininitialize laplacian smoothing\n",
        "train_data = read_data('data/train1.txt') # load the dataset \n",
        "valid_data = read_data('data/valid1.txt') # load the dataset \n",
        "\n",
        "# pass through label renaming function.\n",
        "preprocesed_train = rename_label(train_data, label_mapping) # get new labels \n",
        "preprocesed_valid = rename_label(valid_data, label_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "y1v2WNglYAK-"
      },
      "outputs": [],
      "source": [
        "# counts\n",
        "counts = word_count(preprocesed_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BvDgKVlYK2c",
        "outputId": "07483e81-2f46-4841-aa48-8a31fd8352de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.941"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# now compute accuracy.\n",
        "compute_accuracy(preprocesed_valid, mu, counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
